{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data set**\n",
    "\n",
    "See [Datasets](https://huggingface.co/docs/datasets/index) documentation on HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('files/wine_review.parquet.gzip')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "s = df.sample(n, random_state=42)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timeit(purpose, func, count, items='documents'):\n",
    "  start = time.perf_counter()\n",
    "  try:\n",
    "    return func()\n",
    "  finally:\n",
    "    elapsed = time.perf_counter() - start\n",
    "    display(Markdown(f'It took ${elapsed/60:.1f}$ minutes to {purpose} for ${count:,d}$ {items}.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def compute_embeddings(corpus, model_name='all-mpnet-base-v2'):\n",
    "  # timing helper\n",
    "  __t = lambda purpose, func: timeit(purpose, func, len(corpus), 'reviews')\n",
    "\n",
    "  # Calculate embeddings from pre-trained sentence transformer model\n",
    "  model = SentenceTransformer(model_name)\n",
    "  return __t('compute embeddings', lambda: model.encode(corpus, normalize_embeddings=True, show_progress_bar=True, device='cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_embeddings(embeddings):\n",
    "  # timing helper\n",
    "  __t = lambda purpose, func: timeit(purpose, func, embeddings.shape[0], 'reviews')\n",
    "\n",
    "  # perform t-SNE dimension reduction onto 2D for plotting\n",
    "  tsne = TSNE(perplexity=10, random_state=42)\n",
    "  tsne_result = __t('perform t-SNE dimension reduction on embeddings', lambda: tsne.fit_transform(embeddings))\n",
    "\n",
    "  # create a scatter plot\n",
    "  plt.scatter(tsne_result[:,0], tsne_result[:,1], s=0.005)\n",
    "  plt.title('Wine t-SNE')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the embeddings for the default model, which is all-mpnet-base-v2\n",
    "mpnet_embeddings = compute_embeddings(df.description.to_list())\n",
    "mpnet_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(mpnet_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "wine_dataset = Dataset.from_pandas(s, preserve_index=True)\n",
    "wine_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create HuggingFace Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "model_ckpt = 'sentence-transformers/all-mpnet-base-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "model\n",
    "\n",
    "# Use GPU to speed up embedding process\n",
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Number of CUDA devices: {num_devices}\")\n",
    "    for i in range(num_devices):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions to create Text Embeddings using the HiggingFace Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool token embeddings \n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "  token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "  input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "  return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Function to get the embeddings from wine description input \n",
    "def get_embeddings(text_input):\n",
    "  # Tokenize sentences\n",
    "  encoded_input = tokenizer(text_input, padding=True, truncation=True, return_tensors='pt')\n",
    "  # Compute token embeddings\n",
    "  encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "  with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "  # Perform pooling\n",
    "  text_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "  # Normalize embeddings\n",
    "  text_embeddings = F.normalize(text_embeddings, p=2, dim=1)\n",
    "  return text_embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a review to try out the Embedding Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = wine_dataset[2]\n",
    "description = review['description']\n",
    "tokens = review['preprocessed_description']\n",
    "display(Markdown(f'({len(description)}, {len(description.split(' '))}): ' + description))\n",
    "display(Markdown(f'({len(tokens)}, {len(tokens.split(' '))}): ' + tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try the Embedding Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_embeddings(description).detach().cpu().numpy().shape, get_embeddings(tokens).detach().cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Embeddings on Vector of Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Now create new embeddings column for entire dataset\n",
    "embeddings_dataset = wine_dataset.map(\n",
    "    lambda x: {'embeddings': get_embeddings(x['description'])\n",
    "    .detach().cpu().numpy()})\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took {elapsed/60:.0f} minutes to compute embeddings for {wine_dataset.num_rows:,d} samples.  It will take {df.shape[0]/s.shape[0]*elapsed/60:.0f} minutes to compute embeddings for {df.shape[0]:,d} reviews.'))\n",
    "embeddings_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO determine what this does\n",
    "embeddings_dataset = embeddings_dataset.with_format(\"np\")\n",
    "embeddings_dataset[1]['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat so can work with FAISS\n",
    "def process_embeddings(example):\n",
    "    example['embeddings'] = np.squeeze(example['embeddings']).astype(np.float32)\n",
    "    return example\n",
    "\n",
    "embeddings_dataset = embeddings_dataset.map(process_embeddings)\n",
    "\n",
    "embeddings_dataset[1]['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['__index_level_0__']\n",
    "embeddings_dataset = embeddings_dataset.remove_columns(columns_to_remove)\n",
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_dataset = embeddings_dataset.drop_index(\"embeddings\")\n",
    "# ds_path = \"files/wine_embeddings.hf\"\n",
    "new_ds_path = \"files/wine_ds.hf\"\n",
    "embeddings_dataset.save_to_disk(new_ds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity Search with FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_dataset['embeddings'][0].shape)  # shape of an individual sentence embedding\n",
    "print(len(embeddings_dataset['embeddings']))  # number of sentence embeddings in the \"embeddings\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = embeddings_dataset['embeddings'][132]\n",
    "\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", test_embedding, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in samples['description']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.DataFrame({c: list(samples[c]) for c in samples})\n",
    "samples_df['scores'] = scores\n",
    "samples_df.sort_values('scores', ascending=False, inplace=True)\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index_path = \"files/wine_faiss_index.faiss\" \n",
    "embeddings_dataset.save_faiss_index('embeddings', faiss_index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reloading\n",
    "from datasets import load_dataset, load_from_disk\n",
    "ds_path = \"files/wine_embeddings.hf\"\n",
    "faiss_index_path = \"files/wine_faiss_index.faiss\" \n",
    "\n",
    "ds = load_from_disk(new_ds_path)\n",
    "ds.load_faiss_index('embeddings', faiss_index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Embeddings on Entire Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "start = time.perf_counter()\n",
    "# Now create new embeddings column for entire dataset\n",
    "embeddings_dataset = wine_dataset.map(\n",
    "    lambda x: {'embeddings': get_embeddings(x['description'])\n",
    "    .detach().cpu().numpy()})\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to compute embeddings for ${df.shape[0]:,d}$ reviews.'))\n",
    "\n",
    "# reshape for FAISS index\n",
    "embeddings_dataset = embeddings_dataset.with_format(\"np\")\n",
    "embeddings_dataset = embeddings_dataset.map(process_embeddings)\n",
    "\n",
    "# save embeddings to disk\n",
    "ds_path = \"files/wine_ds.hf\"\n",
    "embeddings_dataset.save_to_disk(ds_path)\n",
    "\n",
    "# add similarity index\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")\n",
    "faiss_index_path = \"files/wine_faiss_index.faiss\"\n",
    "embeddings_dataset.save_faiss_index('embeddings', faiss_index_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"files/wine_ds.hf\"\n",
    "embeddings_dataset = load_from_disk(ds_path)\n",
    "embeddings_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_dataset['embeddings'][0].shape)  # shape of an individual sentence embedding\n",
    "print(len(embeddings_dataset['embeddings']))  # number of sentence embeddings in the \"embeddings\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to pandas \n",
    "embeddings_dataset.set_format(\"pandas\")\n",
    "df = embeddings_dataset[:]\n",
    "print(f\"df shape with duplicates: {df.shape}\")\n",
    "df = df.drop_duplicates(subset='description', keep=\"first\")\n",
    "print(f\"df shape without duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarity Search with FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "test_embedding = embeddings_dataset['embeddings'][132]\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", test_embedding, k=6)\n",
    "samples['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.pop('embeddings')\n",
    "samples.pop('__index_level_0__')\n",
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to pandas \n",
    "embeddings_dataset.set_format(\"pandas\")\n",
    "df = embeddings_dataset[:]\n",
    "print(f\"df shape with duplicates: {df.shape}\")\n",
    "df = df.drop_duplicates(subset='description', keep=\"first\")\n",
    "print(f\"df shape without duplicates: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset pandas df\n",
    "subset_df = df.loc[df['country']=='US', :]\n",
    "subset_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas df tof hf ds\n",
    "subset = Dataset.from_pandas(subset_df.drop('__index_level_0__', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and to NN on new subset\n",
    "subset.reset_format()\n",
    "subset = subset.with_format(\"np\")\n",
    "subset.add_faiss_index(column=\"embeddings\")\n",
    "test_embedding = subset['embeddings'][132]\n",
    "print(test_embedding.shape)\n",
    "scores, samples = subset.get_nearest_examples(\n",
    "    \"embeddings\", test_embedding, k=6)\n",
    "samples['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in samples['description']:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reset from pandas to arrow\n",
    "embeddings_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Varieties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks for analysis\n",
    "\n",
    "varieties = list(df.variety.unique())\n",
    "# Determine the chunk size\n",
    "chunk_size = len(varieties) // 8\n",
    "# Split the list into chunks\n",
    "chunks = [varieties[i:i+chunk_size] for i in range(0, len(varieties), chunk_size)]\n",
    "# Handle any remaining elements\n",
    "if len(chunks) < 8:\n",
    "    chunks[-1].extend(varieties[len(chunks)*chunk_size:])\n",
    "\n",
    "#print chunks\n",
    "for i in range(len(chunks)):\n",
    "    print(chunks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = ['White Blend', 'Pinot Gris', 'Riesling', 'Chardonnay', 'Chenin Blanc', 'Sauvignon Blanc', \n",
    "         'Viognier-Chardonnay', 'Catarratto', 'Inzolia', 'Bordeaux-style White Blend', 'Grillo', \n",
    "         'Albariño', 'Petit Manseng', 'Vernaccia', 'Grüner Veltliner', 'Viognier', 'Vermentino', \n",
    "         'Grenache Blanc', 'Pinot Blanc', 'Alsace white blend', 'Portuguese White', 'Verdejo', \n",
    "         'Fumé Blanc', 'Pinot Bianco', 'Ugni Blanc-Colombard', 'Friulano', 'Assyrtico', 'Vignoles', \n",
    "         'Muscat', 'Muscadelle', 'Garganega', 'Pinot Grigio','Cortese', 'Melon', 'Vidal', 'Verdelho', \n",
    "         'Marsanne', 'Vilana', 'Viura', 'Verduzzo', 'Verdicchio', 'Colombard', 'Sylvaner', 'Sémillon', \n",
    "         'Antão Vaz', 'Verdejo-Viura', 'Chenin Blanc-Chardonnay', 'Insolia', 'Ribolla Gialla', \n",
    "         'Weissburgunder', 'Traminer', 'Prié Blanc', 'Müller-Thurgau', 'Pansa Blanca', 'Muskat Ottonel',\n",
    "        'Sauvignon Blanc-Semillon', 'Semillon-Sauvignon Blanc', 'Bical', 'Viura-Chardonnay', 'Malvasia Bianca',\n",
    "         'Rhône-style White Blend', 'Scheurebe', 'Kerner', 'Carricante', 'Fiano', 'Früburgunder', 'Roussanne', \n",
    "         'Avesso', 'Chinuri', 'Muscat Blanc à Petits Grains', 'Xarel-lo', 'Greco', 'Trebbiano', 'Prié Blanc',\n",
    "        'Falanghina', 'Bical', 'Gelber Muskateller', 'Turbiana', 'Refosco', 'Alvarinho', 'Manzoni', 'Assyrtiko', \n",
    "        'Welschriesling', 'Rieslaner', 'Traminette', 'Marsanne-Viognier', 'Gewürztraminer-Riesling', \n",
    "        'Austrian white blend', 'Tocai', 'Chardonnay-Viognier', 'Fernão Pires', 'Seyval Blanc', 'Muscat Canelli', \n",
    "        'Arinto', 'Arneis', 'Malvasia', 'Altesse', 'Blanc du Bois', 'Provence white blend', 'Nosiola', \n",
    "        'Roussanne-Viognier', 'Godello', 'Auxerrois', 'Albana', 'Muskat',  'Grechetto', 'Encruzado', \n",
    "        'Garnacha Blanca', 'Pallagrello', 'Morava', 'Aleatico', 'Nascetta', 'Siria', 'Asprinio', 'Feteascǎ Regalǎ', \n",
    "        'Tocai Friulano', 'Schiava', 'Chardonnay-Semillon', 'Palomino', 'Norton', \n",
    "        'Loureiro-Arinto', 'Symphony', 'Edelzwicker', 'Madeira Blend', 'Gros and Petit Manseng', 'Jacquère', \n",
    "        'Chenin Blanc-Sauvignon Blanc', 'Marzemino', 'Chardonnay-Sauvignon Blanc', 'Trebbiano Spoletino',\n",
    "        'Chasselas', 'Hárslevelü', 'Siegerrebe','Colombard-Sauvignon Blanc', 'Diamond',\n",
    "        'Gros Manseng', 'Muskateller', 'Aligoté', 'Muscat Blanc', 'Viognier-Roussanne', 'Pallagrello Bianco', \n",
    "        'Veltliner', 'Chardonnay-Sauvignon', 'Chenin Blanc-Viognier', 'Vitovska', 'Grauburgunder', 'Macabeo', \n",
    "        'Verdil', 'Treixadura', 'Coda di Volpe', 'Viura-Verdejo', 'Bombino Bianco', 'Pinot-Chardonnay', \n",
    "        \"Muscat d'Alexandrie\", 'Chardonnay-Pinot Gris', 'Chardonnay-Pinot Blanc','Piquepoul Blanc', 'Orange Muscat',\n",
    "        'Ugni Blanc', 'Semillon-Chardonnay', 'Irsai Oliver', 'Greco Bianco', 'Viognier-Grenache Blanc', 'Pignoletto', \n",
    "        'Muscatel', 'White Riesling', 'Hondarrabi Zuri', 'Nuragus', 'Xynisteri', 'Sauvignon Musqué', 'Roussanne-Marsanne', \n",
    "        'Incrocio Manzoni', 'Terrantez', 'Bual', 'Verdejo-Sauvignon Blanc', 'Malvasia-Viura', 'Savatiano', \n",
    "        'Macabeo-Chardonnay', 'Tamjanika', 'Macabeo-Moscatel', 'Códega do Larinho','Pinot Gris-Gewürztraminer',\n",
    "         'Viosinho', 'Paralleda', 'Malvar', 'Airen', 'Erbaluce', 'Verdosilla', 'Aidani', 'Vinhão', 'Rolle', 'Orangetraube', \n",
    "         'Žilavka', 'Portuguiser', 'Gouveio', 'Bombino Nero', 'Malagouzia-Chardonnay', 'Elbling', 'Gragnano', \n",
    "         'Pinot Blanc-Chardonnay', 'Petit Meslier', 'Chardonnay Weissburgunder', 'Robola', 'Folle Blanche', 'Malagouzia', \n",
    "         'Rabigato', 'Sauvignonasse', 'Meseguera', 'Alvarinho-Chardonnay', 'Pinot Blanc-Viognier', 'Biancu Gentile', \n",
    "         'Xinisteri','Moschofilero-Chardonnay','Sauvignon Blanc-Sauvignon Gris', 'Trebbiano di Lugana', 'Verdeca', \n",
    "         'Chardonel', 'Silvaner-Traminer', 'Uvalino', 'Merseguera-Sauvignon Blanc', 'Cayuga', \n",
    "         'Nasco', 'Vital', 'Apple', 'Pinot Grigio-Sauvignon Blanc', 'Valvin Muscat', 'Malvasia Fina', \n",
    "         'Roditis-Moschofilero', 'Premsal', 'Jampal', 'Tokay Pinot Gris', 'Trajadura', 'Roscetto', 'Torontel', \n",
    "         'Viognier-Valdiguié',\n",
    "         'Zierfandler', 'Marsanne-Roussanne', 'Pinot Meunier', 'Muskat Ottonel', 'Moscatel', 'Moschofilero', 'White Port', \n",
    "         'Kisi', 'Kangoun', 'Posip', 'Uva di Troia', 'Zierfandler-Rotgipfler', 'Mauzac', 'Pinot Auxerrois', 'Neuburger', \n",
    "         'Sämling', 'Rkatsiteli', 'Trousseau Gris', 'Malvasia Istriana', 'Morillon', 'Tokay', 'Gros Plant', 'Muscat Hamburg', \n",
    "         'Emir', 'Tsolikouri', 'Narince', 'Grecanico', 'Madeleine Angevine', 'Doña Blanca', 'Graševina', 'Thrapsathiri', \n",
    "         'Cococciola', 'Plyto', 'Azal', 'Moscatel Graúdo', 'Malvasia di Candia', 'Maria Gomes', 'Muscat of Alexandria', \n",
    "         'Moscatel de Alejandría', 'Misket', 'Tamianka', 'Morio Muskat', 'Sauvignonasse', \n",
    "         'Viognier-Marsanne', 'Ryzlink Rýnský', 'Muscadel', 'Roussanne-Grenache Blanc', 'Chancellor', 'Picapoll', \n",
    "         'Blauburger', 'Athiri', 'Ondenc','Gewürztraminer', 'Torrontés', 'Furmint', 'Savagnin', 'Glera', \n",
    "         'Roter Veltliner', 'Silvaner', 'Ruché', 'Pecorino', 'Sauvignon Gris', 'Vidal Blanc', 'Albanello', \n",
    "         'Loureiro', 'Clairette', 'Verduzzo Friulano ', \"Loin de l'Oeil\", 'Timorasso', 'Pigato', 'Viognier-Gewürztraminer', \n",
    "         'Sauvignon Blanc-Chenin Blanc', 'Colombard-Ugni Blanc', 'Mtsvane', 'Rivaner', 'Vespaiolo', 'Biancolella', \n",
    "         'Riesling-Chardonnay', 'Maria Gomes-Bical', 'Gelber Traminer', 'Sercial', 'Grenache Gris', 'Chardonnay-Albariño',\n",
    "          'Roditis', 'Papaskarasi', 'Zibibbo', 'Malagousia', 'Rotgipfler', 'Durella', 'Cercial', 'Johannisberg Riesling', \n",
    "          'Teran', 'Mantonico', 'Timorasso', 'Zlahtina', 'Shiraz-Roussanne', 'Tămâioasă Românească', 'Ansonica', 'Feteasca',\n",
    "        'Catalanesca', 'Moscato di Noto', 'Moscato Giallo','Sauvignon Blanc-Chardonnay', 'Sauvignon-Sémillon', \"Cesanese d'Affile\", \n",
    "        'Sauvignon Blanc-Verdejo', 'Chardonnay-Riesling', 'Sauvignon Blanc-Assyrtiko','Zelen', 'Tempranillo Blanco', 'Roter Traminer'\n",
    "]\n",
    "red = ['Portuguese Red', 'Pinot Noir', 'Tempranillo-Merlot', 'Frappato', 'Cabernet Sauvignon',\n",
    "        'Nerello Mascalese', 'Malbec', 'Tempranillo Blend', 'Meritage', 'Red Blend', 'Merlot', \n",
    "        \"Nero d'Avola\", 'Gamay', 'Primitivo', 'Sangiovese', 'Cabernet Franc', 'Bordeaux-style Red Blend', \n",
    "        'Aglianico', 'Petite Sirah', 'Touriga Nacional', 'Carmenère', 'Rosso', 'Shiraz-Cabernet Sauvignon', \n",
    "        'Barbera', 'Rhône-style Red Blend', 'Graciano', 'Tannat-Cabernet', 'Sauvignon', 'Sangiovese Grosso', \n",
    "        'Bonarda', 'Shiraz', 'Montepulciano', 'Grenache', 'Syrah', 'Nebbiolo', 'Blaufränkisch', 'Carignan-Grenache', \n",
    "        'Sagrantino', 'Cabernet Sauvignon-Syrah', 'Tempranillo','Mencía', 'Zweigelt', 'Cannonau', 'Dolcetto', \n",
    "        'Garnacha Tintorera', 'Pinot Nero', 'Pinotage', 'Syrah-Grenache', 'Antão Vaz', 'Cabernet Sauvignon-Carmenère', \n",
    "        'Tinta Miúda', 'Monastrell', 'Merlot-Malbec', 'Cabernet Sauvignon-Merlot', 'Merlot-Argaman', 'Garnacha', \n",
    "        'Negroamaro', 'Mourvèdre', 'Syrah-Cabernet', 'Tannat', 'Cabernet Sauvignon-Sangiovese', 'Austrian Red Blend', \n",
    "        'Teroldego', 'Baga','Pinot Noir-Gamay', 'Cinsault', 'Corvina, Rondinella, Molinara', 'Tannat-Syrah', 'Charbono', \n",
    "        'Provence red blend', 'Claret','Malbec-Merlot', 'Monastrell-Syrah', 'Malbec-Tannat', 'Malbec-Cabernet Franc', \n",
    "        'Tinta de Toro', 'Cabernet Moravia', 'Chambourcin', 'Nero di Troia', 'Cesanese', 'Lagrein', 'Tinta Fina', 'St. Laurent', \n",
    "        'Cabernet Sauvignon-Shiraz', 'Syrah-Cabernet Sauvignon', 'Pugnitello', 'Touriga Nacional Blend', 'Tinta Roriz', \n",
    "        'Cabernet Franc-Cabernet Sauvignon', 'Grenache-Syrah', 'Tempranillo-Cabernet Sauvignon', 'Merlot-Cabernet Franc', \n",
    "        'Syrah-Petite Sirah', 'Cabernet Blend', 'Maturana', 'Magliocco', 'Gamay Noir', 'Spätburgunder', 'Plavac Mali',\n",
    "        'Lemberger', 'Saperavi', 'Dornfelder', 'Ojaleshi', 'Mondeuse', 'Perricone', 'Syrah-Merlot', 'Cabernet Sauvignon-Malbec',\n",
    "        'Tinto Fino', 'Malbec-Cabernet Sauvignon','Picpoul','Carignano', 'Cabernet Franc-Merlot', \n",
    "        'Syrah-Petit Verdot', 'Syrah-Mourvèdre', 'Shiraz-Grenache', 'Grenache-Carignan', 'Malbec-Syrah', \n",
    "        'Cabernet Sauvignon-Tempranillo', 'Carignan', 'Cabernet-Syrah', 'Merlot-Cabernet Sauvignon', \n",
    "        'Mourvèdre-Syrah', 'Negrette', 'Tinta Barroca', 'Merlot-Tannat','Castelão', \n",
    "         'Grenache Blend', 'Sangiovese Cabernet', 'Touriga Nacional-Cabernet Sauvignon', 'Cabernet Sauvignon-Cabernet Franc', \n",
    "         'Baco Noir', 'Tempranillo-Tannat', 'Touriga Franca', 'Barbera-Nebbiolo', 'Prieto Picudo', 'Gaglioppo', 'Carignane', \n",
    "         'Tannat-Merlot', 'Nerello Cappuccio', 'Counoise', 'Mazuelo', 'Tinta del Pais', 'Vranec', 'Mavrud', 'Cabernet', \n",
    "         'Grenache-Mourvèdre', 'Forcallà', 'Syrah-Tempranillo', 'Cabernet Sauvignon-Barbera', 'Merlot-Cabernet', 'Jaen', \n",
    "         'Tinta del Toro', 'Prunelard', 'Garnacha-Syrah', 'Rufete', 'Tempranillo-Shiraz','Mansois',\n",
    "         'Mataro', 'Tinta Cao', 'Blauer Portugieser', 'Groppello', 'Poulsard', 'Grenache-Shiraz', 'Baga-Touriga Nacional', \n",
    "         'Carineña', 'Ciliegiolo', 'Cabernet Sauvignon-Merlot-Shiraz', 'Sciaccerellu', 'Alicante', 'Rosenmuskateller', \n",
    "         'Malbec-Cabernet', 'Touriga', 'Carmenère-Syrah', 'Mavroudi', 'Pinot Blanc-Pinot Noir', 'Tinto Velasco', 'Kadarka', \n",
    "         'Sangiovese-Syrah', 'Tannat-Cabernet Franc', 'Fer Servadou', 'Mission', 'Kekfrankos', 'Blauburgunder', 'Marquette', \n",
    "         'Romorantin', 'Braucol', 'Cabernet Franc-Malbec', 'Pallagrello Nero', 'Rebula', 'Vespolina', 'Shiraz-Malbec', \n",
    "         'Rebo', 'Tempranillo-Malbec', 'Trousseau', 'Bacchus', 'Syrah-Malbec', 'Syrah-Cabernet Franc', 'Cariñena-Garnacha', \n",
    "         'Sideritis','Rara Neagra', 'Molinara', 'Abouriou', 'Nielluciu', 'Malbec-Bonarda', 'Garnacha-Monastrell', 'Souzao', \n",
    "         'Tinta Francisca', 'Malvasia Nera', 'Listán Negro', 'Pinotage-Merlot', 'Jacquez', 'Carignan-Syrah', 'Mavrotragano', \n",
    "         'Bovale', 'Frankovka', 'Garnacha Blend', 'Merlot-Shiraz', 'Malbec Blend', 'Merlot-Syrah', 'Babić', 'Yapincak', \n",
    "         'Mandilaria', 'Saperavi-Merlot', 'Teroldego Rotaliano', 'Garnacha-Tempranillo','Vermentino Nero',\n",
    "          'Albarossa', 'Cabernet Sauvignon Grenache', 'Black Monukka', 'Merlot-Grenache', 'Vranac', 'Tempranillo-Syrah', \n",
    "          'Boğazkere', 'Tinta Amarela', 'Tinta Negra Mole', 'Chelois', 'Shiraz-Tempranillo', 'Biancale', 'Syrah-Bonarda', \n",
    "          'Durif', 'Franconia', 'Malbec-Tempranillo', 'Monastrell-Petit Verdot', 'Sirica', 'Espadeiro', 'Blatina', 'Karalahna', \n",
    "          'Garnacha-Cabernet', 'Garnacha-Cariñena', 'Cabernet Franc-Lemberger', 'Shiraz-Mourvèdre', 'Mavrokalavryta', 'Favorita', \n",
    "          'Babosa Negro', 'Dafni', 'Petit Courbu', 'Kotsifali', 'Parraleta', 'Otskhanuri Sapere', 'Trollinger', \n",
    "          'Tsapournakos', 'Francisa', 'Kuntra', 'Pignolo', 'Schwartzriesling','Sousão', 'Feteasca Neagra', 'Kinali Yapincak',\n",
    "          'Kalecik Karasi', 'Karasakiz', 'Raboso', 'Trepat', 'Freisa', 'Trincadeira', 'Melnik', 'Argaman', 'Piedirosso', \n",
    "          'Marawi', 'Çalkarası', 'Tinta Francisca', 'Vidadillo', 'Other', 'Cabernet Pfeffer', 'Roviello', 'Colorino', \n",
    "          'Tinta Madeira', 'Centesimino', 'Ramisco', 'Gamza', 'Bobal-Cabernet Sauvignon',\n",
    "          'Petit Verdot', 'Zinfandel', 'G-S-M', 'Monica', 'Cabernet Merlot', 'Cabernet Franc-Carmenère', \n",
    "          'Grenache Noir', 'Xinomavro', 'Petite Verdot', 'Tempranillo-Garnacha', 'Carmenère-Cabernet Sauvignon', \n",
    "          'Sangiovese-Cabernet Sauvignon', 'Shiraz-Cabernet', 'Syrah-Grenache-Viognier', 'Cabernet-Shiraz', 'Syrah-Carignan', \n",
    "          'Cabernet-Malbec', 'Merlot-Petite Verdot', 'Duras', 'Aragonês', 'Agiorgitiko', 'Aragonez', 'Alfrocheiro', 'Corvina', \n",
    "          'Alicante Bouschet', 'Tinto del Pais', 'Bobal', 'Susumaniello', 'Grolleau', 'Canaiolo', 'Bastardo', 'Tintilia', \n",
    "          'St. Vincent', 'Caprettone','Black Muscat','Muscadine','Syrah-Viognier', 'Shiraz-Viognier', 'Carcajolu', \n",
    "          'Marselan', 'Malbec-Petit Verdot', 'Grignolino', 'Pinot Noir-Syrah', 'Malbec-Carménère','País', 'Alvarelhão', \n",
    "          'Okuzgozu', 'Tintilia','Mavrodaphne','Tintilia ', \n",
    "] \n",
    "rose = ['Rosé', 'Rosato', 'Rosado','Portuguese Rosé', 'Prugnolo Gentile'] \n",
    "sparkling = ['Champagne Blend', 'Prosecco', 'Sparkling Blend','Portuguese Sparkling',\n",
    "             'Cerceal', 'Lambrusco','Lambrusco di Sorbara','Lambrusco Grasparossa',\n",
    "              'Torbato', 'Moscadello', 'Passerina', 'Brachetto', 'Ekigaïna', 'Picolit', \n",
    "              'Sacy', 'Moscatel Roxo', 'Debit','Moscato', 'Valdiguié', 'Casavecchia', \n",
    "              'Lambrusco Salamino', 'Moscato Rosa'] \n",
    "fortified = ['Sherry', 'Pedro Ximénez', 'White Port', 'Tokaji','Port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_dict = {variety: 'red' for variety in red}\n",
    "white_dict = {variety: 'white' for variety in white}\n",
    "rose_dict = {variety: 'rose' for variety in rose}\n",
    "sparkling_dict = {variety: 'sparkling' for variety in sparkling}\n",
    "fortified_dict = {variety: 'fortified' for variety in fortified}\n",
    "wine_dict = {**red_dict, **white_dict, **rose_dict, **sparkling_dict, **fortified_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type_faiss'] = df['variety'].map(wine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.loc[df.type.isnull(), 'variety'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type_faiss.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create TSNE Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your pandas DataFrame\n",
    "embeddings = np.array(df['embeddings'].tolist())  # Convert embeddings column to a numpy array\n",
    "\n",
    "# Perform t-SNE with tqdm progress bar\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "with tqdm(total=len(embeddings), desc=\"Running t-SNE\") as pbar:\n",
    "    tsne_results = tsne.fit_transform(embeddings)\n",
    "    pbar.update(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with colors based on variet\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.005) #, c='type', cmap='viridis')\n",
    "plt.title('Wine t-SNE')\n",
    "#plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Sentence Transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "start = time.perf_counter()\n",
    "embeddings = model.encode(df.description.to_list(), show_progress_bar=True)\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to compute embeddings for ${df.shape[0]:,d}$ reviews.'))\n",
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = df.description.to_list()\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "start = time.perf_counter()\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took ${elapsed:.0f}$ seconds to tokenize for ${df.shape[0]:,d}$ reviews.'))\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "  start = time.perf_counter()\n",
    "  model_output = model(**encoded_input)\n",
    "  elapsed = time.perf_counter() - start\n",
    "  display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to compute embeddings for ${df.shape[0]:,d}$ reviews.'))\n",
    "\n",
    "# Perform pooling\n",
    "start = time.perf_counter()\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to perform pooling of embeddings for ${df.shape[0]:,d}$ reviews.'))\n",
    "\n",
    "# Normalize embeddings\n",
    "start = time.perf_counter()\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "elapsed = time.perf_counter() - start\n",
    "display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to normalize embeddings for ${df.shape[0]:,d}$ reviews.'))\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "sentence_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE with tqdm progress bar\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "start = time.perf_counter()\n",
    "tsne_results = tsne.fit_transform(embeddings)\n",
    "display(Markdown(f'It took ${elapsed/60:.0f}$ minutes to compute t-SNE dimension reductions for ${df.shape[0]:,d}$ reviews.'))\n",
    "tsne_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with colors based on variet\n",
    "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], s=0.005) #, c='type', cmap='viridis')\n",
    "plt.title('Wine t-SNE')\n",
    "#plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
