{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('files/wine_review.parquet.gzip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the Corpus to Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sentences to encode\n",
    "sentences = df.description.to_list()\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper to Time Various Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "PERF = namedtuple('PERF', ['algo', 'duration'])\n",
    "\n",
    "timings = []\n",
    "\n",
    "def timeit(algo, purpose, func, count, items='documents'):\n",
    "  start = time.perf_counter()\n",
    "  result = func()\n",
    "  elapsed = time.perf_counter()-start\n",
    "  timings.append(PERF(algo, elapsed))\n",
    "  display(Markdown(f'It took ${elapsed/60:.1f}$ minutes to {purpose} for ${count:,d}$ {items}.'))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper to Compute Embeddings for a Corpus Given the Name of a Pretrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def compute_embeddings(corpus, model_name='all-MiniLM-L6-v2'):\n",
    "  # timing helper\n",
    "  __t = lambda purpose, func: timeit(model_name, purpose, func, len(corpus), 'reviews')\n",
    "\n",
    "  # calculate embeddings using a pretrained sentence transformer model\n",
    "  model = SentenceTransformer(model_name)\n",
    "  return __t('compute embeddings', lambda: model.encode(corpus, normalize_embeddings=True, show_progress_bar=True, device='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper to compute the t-SNE Dimensional Reduction of Embeddings Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "# from joblib import Parallel, delayed, parallel_config\n",
    "\n",
    "def tsne(embeddings, perplexity=10):\n",
    "  # timing helper\n",
    "  __t = lambda purpose, func: timeit('tsne', purpose, func, embeddings.shape[0], 'reviews')\n",
    "\n",
    "  # perform dimensionsal reduction on features extracted by sentence transformers\n",
    "  pca = PCA(n_components=50, random_state=42)\n",
    "  tsne = TSNE(perplexity=perplexity, random_state=42, n_jobs=1)\n",
    "  return __t('perform t-SNE dimension reduction on embeddings', lambda: tsne.fit_transform(pca.fit_transform(embeddings)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper to Plot the Result of the Dimensional Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = dict(\n",
    "  sparkling='forestgreen',\n",
    "  white='gold',\n",
    "  rose='deeppink',\n",
    "  red='darkred',\n",
    "  dessert='dodgerblue',\n",
    ")\n",
    "\n",
    "def visualize_embeddings(tsne_result, df=df, model_name='all-MiniLM-L6-v2', hue=None):\n",
    "  # Create a scatter plot with colors based on variet\n",
    "  sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], s=0.35, hue=hue, palette=None if hue is None else color_map) #, c='type', cmap='viridis')\n",
    "  plt.title(f'2D t-SNE Plot of {model_name} Embeddings')\n",
    "  if hue is not None:\n",
    "    plt.legend(title=None, loc='lower center', mode='expand', ncol=df.type.shape[0], frameon=False, fancybox=False, markerscale=10, \n",
    "              fontsize='small', bbox_to_anchor=(.0,-0.05,0.9,1), title_fontsize='medium', handletextpad=.45)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Mean Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`all-mpnet-base-v2` Model with 768 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings and similarities vectors\n",
    "mnpet_embeddings = compute_embeddings(sentences, model_name='all-mpnet-base-v2')\n",
    "mnpet_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "  warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "  mnpet_tsne = tsne(mnpet_embeddings)\n",
    "\n",
    "mnpet_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(mnpet_tsne, model_name='all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Mean Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function to Compute Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # Get token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_embeddings(corpus, model_name='all-MiniLM-L6-v2', tokenizer=None, model=None):\n",
    "  # Load tokenizer and model\n",
    "  tokenizer__ = AutoTokenizer.from_pretrained(model_name) if tokenizer is None else tokenizer\n",
    "  model__ = AutoModel.from_pretrained(model_name) if model is None else model\n",
    "  device = torch.device('cpu')\n",
    "  model__.to(device)\n",
    "\n",
    "  # Tokenize sentences\n",
    "  encoded_input = tokenizer__(sentences, padding=True, truncation=True, return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "  # Get token embeddings\n",
    "  with torch.no_grad():\n",
    "      model_output = model__(**encoded_input)\n",
    "\n",
    "  # Apply mean pooling to get sentence embeddings\n",
    "  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "  # Normalize the embeddings\n",
    "  return F.normalize(sentence_embeddings, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`all-mpnet-base-v2` Model with 768 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings=get_embeddings(sentences, model_name='all-mpnet-base-v2')\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled_mnpet_tsne = tsne(sentence_embeddings)\n",
    "mean_pooled_mnpet_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_embeddings(mean_pooled_mnpet_tsne, model_name='all-mpnet-base-v2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
